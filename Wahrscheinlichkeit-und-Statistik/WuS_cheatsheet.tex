% Basic stuff
\documentclass[a4paper,10pt]{article}
\usepackage[nswissgerman]{babel}

% 3 column landscape layout with fewer margins
\usepackage[landscape, left=0.75cm, top=1cm, right=0.75cm, bottom=1.5cm, footskip=15pt]{geometry}
\usepackage{flowfram}
\ffvadjustfalse
\setlength{\columnsep}{1cm}
\Ncolumn[<10]{3}
\onecolumn[10]

\usepackage[dvipsnames]{xcolor}

% define nice looking boxes
\usepackage[many]{tcolorbox}

% a base set, that is then customised
\tcbset {
	base/.style={
		boxrule=0mm,
		leftrule=1mm,
		left=1.75mm,
		arc=0mm, 
		fonttitle=\bfseries, 
		colbacktitle=black!10!white, 
		coltitle=black, 
		toptitle=0.75mm, 
		bottomtitle=0.25mm,
		title={#1}
	}
}

\definecolor{color-wus}{RGB}{20, 143, 173}
\newtcolorbox{mainbox}[1]{
	colframe=color-wus, 
	base={#1}
}

\newtcolorbox{subbox}[1]{
	colframe=black!20!white,
	base={#1}
}

% Mathematical typesetting & symbols
\usepackage{amsthm, mathtools, amssymb} 
\usepackage{marvosym, wasysym}
\allowdisplaybreaks

% Tables
\usepackage{tabularx, multirow}
\usepackage{makecell}
\usepackage{booktabs}
\renewcommand*{\arraystretch}{2}

% Make enumerations more compact
\usepackage{enumitem}
\setitemize{itemsep=0.5pt}
\setenumerate{itemsep=0.75pt}

% To include sketches & PDFs
\usepackage{graphicx}

% For hyperlinks
\usepackage{hyperref}
\hypersetup{
	colorlinks=true
}

% Metadata
\title{Cheatsheet\\ Wahrscheinlichkeit \& Statistik}
\author{Julian Steinmann}
\date{\vspace{-10pt}Sommersession 2023}

% Math helper stuff
\def\limxo{\lim_{x\to 0}}
\def\limxi{\lim_{x\to\infty}}
\def\limxn{\lim_{x\to-\infty}}
\def\R{\mathbb{R}}
\def\P{\mathbb{P}}
\def\F{\mathcal{F}}
\def\E{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}


\begin{document}

\small

\maketitle

\input{../license.tex}

\section{Grundbegriffe}
\begin{subbox}{Definition Wahrscheinlichkeitsraum}
	Ein Wahrscheinlichkeitsraum ist ein Tupel \((\Omega, \F, \P)\):
	\begin{itemize}
		\item Die Menge \(\Omega\) nenen wir \textbf{Grundraum}. Ein \(\omega \in \Omega\) nennen wir Elementarereignis.
		\item \(\F \subseteq \P(\Omega)\) ist eine \textbf{Sigma-Algebra}.
		\item \(\P\) ist ein \textbf{Wahrscheinlichkeitsmass} definiert auf \((\Omega, \F)\).
	\end{itemize}
	Dabei ist \(A \subseteq \Omega\) ein Ereignis.
\end{subbox}

\subsection{Sigma-Algebra}
Eine Sigma-Algebra ist eine Teilmenge \(\F \subseteq \mathcal{P}(\Omega)\) mit den folgenden Eigenschaften:
\begin{enumerate}
	\item \(\Omega \in \F\)
	\item \(A \in \F \implies A^\complement \in \F\)
	\item \(A_1, A_2, \ldots \in \F \implies \bigcup_{i=1}^\infty A_i \in \F\)
	\item \(\varnothing \in \F\)
	\item \(A_1, A_2, \ldots \in \F \implies \bigcap_{i=1}^\infty A_i \in \F\)
	\item \(A, B \in \F \implies A \cup B \in \F\)
	\item \(A, B \in \F \implies A \cap B \in \F\)
\end{enumerate}
Nützlich ist ausserdem die De-Morgan-Regel: \[(\bigcup_{i=1}^\infty A_i)^\complement = \bigcap_{i=1}^\infty(A_i)^\complement\]

\subsection{Wahrscheinlichkeitsmass}
Ein Wahrscheinlichkeitsmass \(\P\) ist eine Abbildung
\begin{align*}
	\P: \  & \F \mapsto \left[0,1\right] \\
	       & A \mapsto \P[A]
\end{align*}
mit den Eigenschaften
\begin{enumerate}
	\item \(\P[\Omega] = 1\)
	\item \(\P [A] = \sum_{i=1}^\infty P[A_i]\), falls \(A = \bigsqcup_{i=1}^\infty A_i\)
	\item \(\P[\varnothing] = 0\)
	\item \(\P[A^\complement] = 1 - \P[A]\)
	\item \(\P[A \cup B] = \P[A] + P[B] - \P[A\cap B]\)
	\item \(A \subseteq B \implies \P[A] \le \P[B]\) (Monotonie)
	\item \(\P[\bigcup_{i=1}^\infty A_i] \le \sum_{i=1}^\infty \P[A_i]\) (Union Bound)
\end{enumerate}

Wenn \(A_1, \ldots A_n\) paarweise disjunkt sind, gilt:
\[\P[A_1 \cup \ldots \cup A_n] = \P[A_1] + \ldots + \P[A_n]\]

\subsection{Bedingte Wahrscheinlichkeit}
Sei \((\Omega, \F, \P)\) ein Wahrscheinlichkeitsraum mit \(A, B \in \F\) und \(\P[B] > 0\). Die bedingte Wahrscheinlichkeit von \(A\) gegeben \(B\) ist definiert als:
\[\P[A|B] = \frac{\P[A\cap B]}{\P[B]}\]
\begin{subbox}{Totale Wahrscheinlichkeit}
	Sei \(B_1, \ldots, B_n \in \F\) eine Partition von \(\Omega\) mit \(\P[B_i] > 0\) für alle \(1 \le i \le n\). Dann gilt:
	\[\forall A \in \F \: \P[A] = \sum_{i=1}^{n} \P[A|B_i] \ \P[B_i]\]
\end{subbox}
\begin{mainbox}{Satz von Bayes}
	Sei \(B_1, \ldots, B_n \in \F\) eine Partition von \(\Omega\) mit \(\P[B_i] > 0\) für jedes \(i\). Für jedes Ereignis \(A\) mit \(\P[A] > 0\) gilt:
	\[\forall i = 1,\ldots, n \: \P[B_i|A] = \frac{\P[A|B_i] \ \P[B_i]}{\sum_{k=1}^n \P[A|B_k] \ \P[B_k]}\]
\end{mainbox}

\subsection{Unabhängigkeit}
\begin{mainbox}{Definition Unabhängigkeit}
	Zwei Ereignisse \(A, B\in \F\) sind unabhängig, falls gilt:
	\[\P[A\cap B] = \P[A] \cdot \P[B]\]
	Alternative Definitionen sind:
	\[\P[A|B] = \P[A] \text{ bzw. } \P[B|A] = \P[B]\]
\end{mainbox}
\begin{itemize}
	\item Falls \(\P[A] \in \{0,1\}\), dann ist \(A\) zu jedem Ereignis unabhängig.
	\item Wenn ein Ereignis \(A\) unabhängig zu sich selbst ist, dann folgt \(\P[A] \in \{0,1\}\).
	\item Wenn \(A, B\) unabhängig sind, dann sind auch \(A, B^\complement\) unabhängig.
\end{itemize}
\subsubsection*{Unabhängigkeit für mehrere Ereignisse}
Seien \(A_1, \ldots, A_n \in F\), dann sind die Ereignisse unabhängig, falls gilt:
\[\forall I \subseteq \{1, \ldots, n\} \: \P[\bigcap_{i\in I}A_i] = \prod_{i\in I} \P[A_i]\]

\section{Zufallsvariablen}
Eine Zufallsvariable ist eine Abbildung \(X: \Omega \mapsto \R\) mit
\[\forall x \in \R \: \{\omega \in \Omega \mid X(\omega) \leq x\} \in \F\]
Dabei lassen wir das \(\omega\) oft weg und schreiben nur \(X\).

\subsection{Verteilungsfunktion}
\begin{mainbox}{Definition Verteilungsfunktion}
	Die Verteilungsfunktion ist die Abbildung \(F_X: \ \R \mapsto [0,1]\) definiert durch
	\[\forall x \in \R \: F_X(x) = \P[X \le x]\]
\end{mainbox}
Die Verteilungsfunktion hat folgende Eigenschaften:
\begin{enumerate}
	\item \(a < b \implies \P[a < X \le b] = F_X(b) - F_X(a)\)
	\item \(F\) ist monoton wachsend
	\item \(F\) ist rechtsstetig, d.h. \(\lim_{t \to 0} F_{x+t} = F(x)\)
	\item \(\lim_{x\to - \infty} F_X(x) = 0\) und \(\lim_{x\to \infty} F_X(x) = 1\)
\end{enumerate}
\subsubsection*{Linksstetigkeit}
Die Definition der Linksstetigkeit ist
\[F(x-) = \lim_{t\to 0} F(x-t)\]
Es gilt allerdings \textit{nicht} immer \(F(x-) = F(x)\), d.h. nicht jede Verteilungsfunktion ist linksstetig. Allerdings gilt:
\[\forall x \in \R \: F(x) - F(x-) = \P[X=x]\]
Daraus lässt sich für stetige ZV \(P[X=x] = 0\) folgern.
\subsection{Unabhängigkeit}
Die Zufallsvariablen \(X_1, \ldots, X_n\) sind unabhängig, falls:
\begin{align*}
	\forall x_1, \ldots, x_n \in \R \quad & \P[X_1 \le x_1, \ldots, X_n \le x_n] =             \\
	                                       & \P[X_1 \le x_1] \cdot \ldots \cdot \P[X_n \le x_n]
\end{align*}
Eine Folge von Zufallsvariablen \(X_1, X_2, \ldots\) ist unabhängig, falls \(
\forall n \: X_1, \ldots X_n\) unabhängig sind. Sie ist zusätzlich identisch verteilt (uiv.), falls ausserdem \(\forall i,j \: F_{X_i} = F_{X_j}\) gilt.
\subsection{Transformationen}
Sei \(\varphi: \ \R \mapsto \R\) und \(X\) eine Zufallsvariable, so ist
\[\varphi(X) = \varphi \circ X\]
auch eine Zufallsvariable. Seien \(X_1, \ldots, X_n\) ZVs mit \(\phi: \R^n \mapsto \R\), so ist
\[\phi(X_1, \ldots, X_n) = \phi \circ (X_1, \ldots, X_n)\]
ebenfalls eine Zufallsvariable.

\subsection{Konstruktion einer Zufallsvariable}
Gegeben eine Verteilungsfunktion \(F_X\) wollen wir die entsprechende ZV \(X\) konstruieren.
\begin{subbox}{Kolmogorov-Theorem}
	Es existiert \((\Omega, \F,\P)\) und ZVs \( X_1, X_2, \ldots\), sodass \(X_1, X_2, \ldots\) uiv. Bernoullivariablen mit \(p = 0.5\) sind.
\end{subbox}

Sei \(X_1, X_2,\ldots \sim \text{Ber}(\frac{1}{2})\) eine unendliche Folge, dann ist
\[U = \sum_{n = 1}^\infty 2^{-n}\cdot X_n\]
gleichverteilt auf \([0,1]\).

Aufgrund der Eigenschaften der Verteilungsfunktion \(F\) wissen wir, dass eine eindeutige Inverse $F^{-1}$ existiert. Wir können die generalisierte Inverse definieren als: \[\forall \alpha \in [0,1] \: F^{-1}(\alpha) = \inf \{x \in \R \mid F(x) \geq \alpha\}\]

Sei nun \(F\) eine Verteilungsfunktion und \(U\) eine gleichverteilte ZV in \([0,1]\). Dann besitzt \(X = F^{-1}(U)\) genau die Verteilungsfunktion \(F_X = F\).

\begin{subbox}{Fast sichere Ereignisse}
	Ein Ereignis \(A \in \F\) tritt fast sicher (f.s.) ein, falls \(\P[A] = 1\). Seien \(X, Y\) ZV, so schreiben wir \(X \le Y \text{ f.s.} \iff \P[X\le Y] = 1\).
\end{subbox}

\subsection{Diskrete Zufallsvariablen}
\begin{subbox}{Definition diskrete ZV}
	Eine ZV \(X\) heisst diskret, falls \(\exists W \subset \R\) endlich oder abzählbar, so dass \(X \in W\) f.s. Falls \(\Omega\) endlich oder abzählbar ist, dann ist \(X\) immer diskret.
\end{subbox}
\noindent Die Verteilungsfunktion einer diskreten ZV ist:
\[(p(x))_{x \in W} \text{ wobei } \sum_{x\in W} p(x) = 1\]
Die Gewichtsfunktion einer diskreten ZV ist:
\[\forall x \in W \: p(x) = \P[X=x]\]

\subsection{Diskrete Verteilungen}
\begin{mainbox}{Bernoulli-Verteilung (\(X \sim \text{Ber}(p)\))}
    Hat nur die Ereignisse \(\{0,1\}\). Sie ist definiert als
    \[\P[X=0] = 1-p \text{ und } \P[X=1]=p\]
\end{mainbox}
Beispiel Bernoulli-Verteilung: Ergebnis eines Münzwurfs (Kopf oder Zahl).

\begin{mainbox}{Binomialverteilung (\(X \sim \text{Bin}(n,p)\))}
    Die Wiederholung von Bernoulli-Experimenten. Sie ist definiert als
    \[\forall k \in \{0, \ldots, n\} \: \P[X=k] = \binom{n}{k} \cdot p^k \cdot (1-p)^{n-k}\]
\end{mainbox}
Beispiel Binomialverteilung: Anzahl der erfolgreichen Münzwürfe (Köpfe) in einer bestimmten Anzahl von Versuchen.

\begin{mainbox}{Geometrische Verteilung (\(X \sim \text{Geom}(p)\))}
    Beschreibt das erste Auftreten eines Erfolges. Sie ist definiert als
    \[\forall k \in \mathbb{N} - \{0\} \: \P[X=k]=(1-p)^{k-1}\cdot p\]
\end{mainbox}
Beispiel geometrische Verteilung: Anzahl der Münzwürfe, die benötigt werden, um den ersten Erfolg (Kopf) zu erzielen.

\begin{mainbox}{Poisson-Verteilung (\(X \sim \text{Poisson}(\lambda)\))}
    Annäherung an die Binomialverteilung für grosse \(n\) und kleine \(p\) (d.h. rare Ereignisse). Sie ist definiert als
    \[\forall k \in \mathbb{N}, \lambda > 0 \: \P[X=k]=\frac{\lambda^k}{k!}\cdot e^{-\lambda}\]
\end{mainbox}
Beispiel Poisson-Verteilung: Anzahl der Anrufe, die ein Call-Center pro Stunde erhält. Die Poisson-Verteilung wird oft verwendet, um seltene Ereignisse in einem festen Zeitintervall zu modellieren.

\subsection{Stetige Zufallsvariablen}
\begin{subbox}{Definition stetige ZV}
	Eine ZV \(X\) heisst stetig, wenn ihre Verteilungsfunktion \(F_X\) wie folgt geschrieben werden kann:
	\[\forall x \in \R \: F_X(x) = \int_{-\infty}^x f(y) \mathop{dy}\]
\end{subbox}
Hierbei ist \(f: \R \mapsto \R_+\) die Dichte von X. Für die Dichte gilt:
\[\int_{-\infty}^{+\infty}f(y) \mathop{dy} = 1\]
Es gelten folgende Eigenschaften:
\begin{enumerate}
	\item \(\P[a \le x \le b] = \P[a < x < b]\)
	\item \(\P[X=x] = 0\)
	\item \(\P[X \in [a,b]] = \P[X \in (a,b)]\)
\end{enumerate}

\subsection{Stetige Verteilungen}
\begin{mainbox}{Gleichverteilung (\(X \sim \mathcal{U}[a,b]\))}
    Jedes Ereignis hat die gleiche Wahrscheinlichkeit. Sie ist definiert als
    \[f_{a,b}(x) = \begin{cases}
    		0             & x \notin [a,b] \\
    		\frac{1}{b-a} & x \in [a,b]
    \end{cases}\]
\end{mainbox}

\begin{mainbox}{Exponentialverteilung (\(X \sim \text{Exp}(\lambda)\))}
    Das stetige Gegenstück zur Geometrischen Verteilung. Sie ist definiert als
    \[f_{a,b}(x) = \begin{cases}
		0                            & x < 0    \\
		\lambda \cdot e^{-\lambda x} & x \geq 0
	\end{cases}\]
\end{mainbox}
\begin{itemize}
	\item Wenn \(Y\sim \text{Exp}(\lambda)\), dann ist \(c \cdot Y \sim \text{Exp}(\frac{\lambda}{c})\)
	\item \(X_1, X_2 \sim \mathcal{N}(0,1)\) uiv. \(\implies \chi_2 = X_1^2 +X_2^2 \sim \text{Exp}(\frac{1}{2})\)
\end{itemize}

\begin{mainbox}{Normalverteilung (\(X \sim \mathcal{N}(m, \sigma^2)\))}
    Die wohl wichtigste Verteilung. Sie ist definiert als
    \[f_{m, \sigma}(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \cdot e^{-\frac{(x-m)^2}{2 \sigma^2}}\]
\end{mainbox}
\(X \sim \mathcal{N}(0,1)\) wird auch Standardnormalverteilung genannt. Für eine standardnormalverteilte ZV \(X\) gilt
\[Z = m +\sigma \cdot X \sim \mathcal{N}(m, \sigma^2)\]

\section{Erwartungswert}
\begin{mainbox}{Definition Erwartungswert}
	Sei \(X: \Omega \mapsto \R_+\) eine ZV mit nicht-negativen Werten. Dann ist
	\[\E[X] = \int_0^\infty 1- F_X(x) \mathop{dx}\]
	der Erwartungswert von \(X\).
\end{mainbox}
Wenn \(\E[|X|] < \infty\), dann ist der Erwartungswert definiert als
\[\E[X] = \E[X_+] - \E[X_-]\]

\subsection{Erwartungswert diskreter ZV}
Sei \(X\) eine diskrete ZV mit \(X \in W\) f.s. Sei \(\phi: \R \mapsto \R\) eine Abbildung. Falls die Summe wohldefiniert ist, gilt
\[\E[\phi(X)] = \sum_{x\in W} \phi(x)\cdot \P[X=x]\]
Sei \(\phi = \) id, gilt
\[
	\E[X] = \sum_{x\in W} x \cdot \P[X=x]
	.\]

\subsection{Erwartungswert stetiger ZV}
Sei \(X\) eine stetige ZV mit Dichtefunktion \(f\). Sei \(\phi :\R\mapsto \R\) eine Abbildung, sodass \(\phi(x)\) eine Zufallsvariable ist. Sofern das Integral wohldefiniert ist, gilt
\[\E[\phi(X)] = \int_{-\infty}^{\infty}\phi(x)f(x) \mathop{dx}\]
Die Definition für \(\phi = \) id ist analog zum diskreten Fall.
\subsubsection{\texorpdfstring{Bestimmen der Dichte von \(f(X)\)}{Bestimmen der Dichte von f(X)}}
\begin{enumerate}
	\item Sei \(\phi: \R \mapsto \R\) stückweise beschränkt und stetig
	\item \(\E[\phi(Y)] = \E[\phi(f(X))] = \E[\tau(X)]\)
	\item Dichte von \(X\) in vorheriger Gleichung einsetzen
	\item Variablenwechsel \(u = f(x)\) und Grenzen anpassen
\end{enumerate}

\subsection{Rechnen mit Erwartungswerten}
\begin{subbox}{Linearität des Erwartungswertes}
	Seien \(X,Z\) ZV mit \(\lambda \in \R\). Falls die Erwartungswerte wohldefiniert sind, gilt
	\begin{align*}
		\E[\lambda \cdot X] & = \lambda \cdot \E[X] \\
		\E[X + Y]           & = \E[X] + \E[Y]       \\
	\end{align*}
\end{subbox}
Falls zwei ZV \(X,Y\) unabhängig sind, gilt auch
\[\E[X\cdot Y] = \E[X] \cdot \E[Y]\]

Für Divison hingegen gilt:
\[\E[\frac{X}{Y}] = \E[X] \cdot \E[\frac{1}{Y}]\]

\begin{subbox}{Alternativdefinition unabhängige ZV}
	Seien \(X_1, \ldots, X_n\) diskrete ZV. Dann sind folgende Aussagen äquivalent:
	\begin{enumerate}
		\item \(X_1, \ldots, X_n\) sind unabhängig.
		\item Für jedes \(\phi_1, \ldots, \phi_n: \R \mapsto \R\) beschränkt gilt:
        \begin{multline*}
            \E[\phi_1(X_1)\cdot\ldots\cdot\phi_n(X_n)] =\\
            \E[\phi_1(X_1)] \cdot\ldots\cdot \E[\phi_n(X_n)]
        \end{multline*}
	\end{enumerate}
\end{subbox}

\subsection{Extremwertformel}
Sei \(X\) eine diskrete ZV mit Werten in \(\mathbb{N}\). Dann gilt folgende Identität:
\[\E[X] = \sum_{n=1}^\infty \P[X\ge n]\]
Sei \(X\) eine stetige ZV mit \(X \ge 0\) f.s., dann gilt:
\[\E[X] = \int_0^\infty \P[X > x] \mathop{dx}\]

\subsection{Ungleichungen}
\begin{subbox}{Monotonie}
	Seien \(X, Y\) ZV sodass \(X \le Y\) f.s., dann gilt \(\E[X] \le \E[Y]\).
\end{subbox}

\begin{mainbox}{Markov-Ungleichung}
	Sei \(X\) eine ZV mit \(X \ge 0\) f.s., dann gilt für jedes \(a > 0\):
	\[\P[X\ge a] \le \frac{\E[X]}{a}\]
\end{mainbox}

\begin{subbox}{Jensen-Ungleichung}
	Sei \(X\) eine ZV und \(\phi : \R \mapsto \R\) eine konvexe Funktion, dann gilt:
	\[\phi(\E[X]) \le \E[\phi(X)]\]
\end{subbox}

\subsection{Varianz}
Sei \(X\) eine ZV sodass \(\E[X^2] < \infty\). Die Varianz von \(X\) ist definiert durch
\[\Var(X) = \sigma_X^2 = \E[(X-m)^2]\]
wobei \(m=\E[X]\). Dabei wird \(\sigma_X\) auch die Standardabweichung von \(X\) genannt und beschreibt die typische Distanz eines Wertes \(x\in X\) zu \(\E[X]\).

\begin{subbox}{Chebychev-Ungleichung}
	Wenn \(X\) eine ZV mit \(\E[X^2] < \infty\) ist, dann gilt für jedes \(a \ge 0\):
	\[\P[|X - \E[X]| \ge a] \le \frac{\sigma_X^2}{a^2}\]
\end{subbox}

\begin{enumerate}
	\item Wenn \(\E[X^2] < \infty\), dann \(\sigma_X^2 = \E[X^2] - \E[X]^2\).
	\item Wenn \(\E[X^2] < \infty\) und \(\lambda \in \R\), dann \(\sigma_{\lambda X}^2 = \lambda^2\sigma_X^2\).
	\item Wenn \(S = X_1 + \ldots + X_n\), wobei \(X_1, \ldots, X_n\) paarweise unabhängig sind, dann gilt \(\sigma_S^2 = \sigma_{X_1}^2 + \ldots + \sigma_{X_n}^2\).
\end{enumerate}

\subsection{Kovarianz}
Wir können mit der Kovarianz die Abhängigkeit von zwei Zufallsvariablen messen.
\begin{subbox}{Definition Kovarianz}
	Wenn \(X, Y\) zwei ZV mit \(\E[X^2] < \infty, \E[Y^2] < \infty\), dann ist die Kovarianz zwischen \(X, Y\) definiert als
	\[\text{Cov}(X,Y) = \E[X \cdot Y] - \E[X] \cdot \E[Y]\]
\end{subbox}
\begin{itemize}
	\item \(\text{Cov}(X,X) = \sigma_X^2\)
	\item X, Y unabhängig \(\implies \text{Cov}(X,Y) = 0\)
\end{itemize}

\section{Gemeinsame Verteilungen}
\subsection{Diskrete gemeinsame Verteilungen}
\begin{subbox}{Definition gemeinsame Verteilung}
	Seien \(X_1, \ldots, X_n\) diskrete Zufallsvariablen wobei \(X_i \in W_i\) f.s. für \(W_i \subset \R\). Die gemeinsame Verteilung (GV) von \(X_1, \ldots, X_n\) ist die Familie \(p = (p(x_1, \ldots, x_n))_{x_1 \in W_1, \ldots, x_n \in W_n}\) definiert durch
	\[p(x_1, \ldots, x_n) = \P[X_1 = x_1, \ldots, X_n = x_n]\]
\end{subbox}

Seien \(X_1,\ldots,X_n\) diskrete ZV mit \(X_i \in W_i\) f.s. für \(W_i \subset \R\) und \(\phi: \R^n \mapsto \R\), so ist \(Z = \phi(X_1, \ldots, X_n)\) eine diskrete ZV mit Werten in \(W = \phi(W_1 \times \ldots \times W_n)\) und folgender Verteilung:
\[\forall z \in W. \: \P[Z = z] = \sum_{\substack{\phi(x_1, \ldots, x_n) \\= z}} \P[X_1 = x_1, \ldots, X_n = x_n]\]

Seien \(X_1,\ldots,X_n\) diskrete ZV mit \(X_i \in W_i\) f.s. mit GV \(p\). Dann ist die \emph{Randverteilung} \(\forall z \in W_i\):
\[\P[X_i = z] = \sum_{\substack{x_1, \ldots, x_{i-1}, \\x_{i+1},\ldots,x_n}} p(x_1, \ldots, x_{i-1}, z, x_{i+1},\ldots,x_n)\]

Seien \(X_1,\ldots,X_n\) diskrete ZV mit GV \(p\) und \(\phi : \R^n \mapsto \R\). Dann ist der \emph{Erwartungswert} definiert als:
\[\E[\phi(X_1, \ldots, X_n)] = \sum_{x_1,\ldots,x_n} \phi(x_1,\ldots,x_n) \cdot p(x_1,\ldots,x_n)\]

Seien \(X_1,\ldots,X_n\) diskrete ZV mit GV \(p\), dann sind die folgenden Aussagen äquivalent:
\begin{enumerate}
	\item \(X_1,\ldots,X_n\) sind unabhängig
	\item Für alle \(x_1 \in W_1, \ldots, x_n \in W_n\) gilt:
	      \(p(x_1,\ldots,x_n) = \P[X_1 = x_1] \cdot \ldots \cdot \P[X_n = x_n]\)
\end{enumerate}

Die gemeinsame Verteilung von \(X_1, \ldots, X_n\) erfüllt
\[\sum_{x_1\in W_1, \ldots, x_n \in W_n} p(x_1, \ldots, x_n) = 1\]

\subsection{Stetige gemeinsame Verteilungen}
\begin{subbox}{Definition gemeinsame Verteilung}
	Seien \(X_1, \ldots, X_n\) stetige ZV, so haben sie eine gemeinsame Verteilung, falls eine Funktion \(f: \R^n \mapsto \R_+\) existiert, die für jedes \(a_1, \ldots, a_n \in \R\) folgende Eigenschaft erfüllt:
	\begin{multline*}
		\P[X_1 \le a_1, \ldots, X_n \le a_n] = \\
        \int_{-\infty}^{a_1} \cdots \int_{-\infty}^{a_n} f(x_1, \ldots, x_n) \mathop{dx_n} \ldots \mathop{dx_1}
	\end{multline*}
	Dann ist \(f\) die \textbf{gemeinsame Dichte}.
\end{subbox}

Seien \(X_1, \ldots, X_n\) stetige ZV mit einer gemeinsamen Dichte \(f\) und \(\phi: \R^n \mapsto \R\). Dann ist der Erwartungswert definiert als
\begin{multline*}
	\E[\phi(X_1, \ldots, X_n)] = \\
    \int_{-\infty}^\infty \cdots \int_{-\infty}^\infty \phi(x_1, \ldots, x_n) f(x_1, \ldots, x_n) \mathop{dx_n} \ldots \mathop{dx_1}
\end{multline*}

Falls \(X_1, \ldots, X_n\) eine gemeinsame Dichte \(f\) besitzen, ist die Randverteilung
\begin{multline*}
	f_i(z) = \int_{x_1, \ldots, x_{i-1}, x_{i+1}, \ldots, x_n \in \R^{n-1}}               \\
	f(x_1, \ldots, x_{i-1}, z, x_{i+1}, \ldots, x_n) \mathop{dx_n} \ \ldots \mathop{dx_1} \\
\end{multline*}

Wenn \(X_1, \ldots, X_n\) stetige ZV mit Dichten \(f_1, \ldots, f_n\) sind, dann sind die folgenden Aussagen äquivalent:
\begin{enumerate}
	\item \(X_1, \ldots, X_n\) sind unabhängig
	\item \(X_1, \ldots, X_n\) sind stetig mit gemeinsamer Dichte
	      \[f(x_1, \ldots, x_n) = f_1(x_1) \cdot \ldots \cdot f_n(x_n)\]
	\item Für alle \(\phi_1, \ldots, \phi_n: \R \mapsto \R\) gilt:
	      \[\E[\phi_1 (x_1)\cdot \ldots\cdot (x_n)] = \E[\phi_1(x_1)] \cdot \ldots \cdot \E[\phi_n(x_n)]\]
\end{enumerate}

\section{Grenzwertsätze}
Sei \(X_1, X_2, \ldots\) eine unendliche Sequenz an uiv. ZV. Wir betrachten die Teilsumme \(S_n = X_1 + \ldots + X_n\).
\begin{mainbox}{Gesetz der grossen Zahlen}
	Sei \(\E[|X_1|] < \infty\) und \(m = \E[X_1]\), so gilt
	\[\lim_{n\to \infty} \frac{X_1 + \ldots + X_n}{n} = m \quad \text{f.s.}\]
\end{mainbox}
Da die ZV uiv. sind, gilt \(\E[|X_i|] < \infty\) und \(m = \E[X_i]\) auch für alle \(i\).

\subsubsection*{Konvergenz in Verteilung}
Seien \((X_n)_{n\in \mathbb{N}}\) und \(X\) ZV. Wir schreiben
\[X_n \approx X \quad \text{für } n \to \infty\]
falls \(\forall x \in \R\) gilt:
\[\lim_{n\to\infty} \P[X_n \le x] = \P[X \le x ]\]

\begin{mainbox}{Zentraler Grenzwertsatz}
	Sei \(\E[X^2_1] < \infty\) und wohldefiniert. Weiter sei \(m = \E[X_1]\) und \(\sigma^2 = \Var(X_1)\), so gilt:
	\begin{align*}
		\P\left[\frac{S_n - nm}{\sqrt{\sigma^2 n}} \leq a\right] \xrightarrow[n \to \infty]{} \Phi(a) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^a e^{\frac{-x^2}{2}} \mathop{dx}
	\end{align*}
\end{mainbox}
Der zentrale Grenzwertsatz sagt aus, dass die Verteilung einer ZV
\[Z_n = \frac{S_n - nm}{\sqrt{\sigma^2 n}}\]
wie die Verteilung von \(\mathcal{N}(0,1)\) aussieht. Es gilt
\[Z_n \approx Z \quad \text{für } n\to \infty\]
wobei \(Z \sim \mathcal{N}(0,1)\). Für normalverteilte ZV \(X_1, \ldots, X_n\) ist \(Z_n\) immer standardnormalverteilt.

\section{Schätzer}
Wir treffen folgende Annahmen:
\begin{itemize}
	\item Parameterraum \(\Theta \subset \R\)
	\item Familie von Wahrscheinlichkeitsmassen \((\P_\theta)_{\theta \in \Theta}\) auf \((\Omega, \F)\); für jedes Element im Parameterraum existiert ein Wahrscheinlichkeitsmodell
	\item Zufallsvariablen \(X_1, \ldots, X_n\) auf \((\Omega, \F)\)
	\item Wir nennen die Gesamtheit der beobachteten Daten \(x_1, \ldots, x_n\) oder der ZV \(X_1, \ldots, X_n\) Stichprobe
\end{itemize}
\begin{mainbox}{Definition Schätzer}
	Ein Schätzer ist eine Zufallsvariable \(T: \Omega \mapsto \R\) von der Form
	\[T = t(X_1, \ldots, X_n), \quad t: \R^n \mapsto \R\]
\end{mainbox}
Ein Schätzer \(T\) ist \emph{erwartungstreu}, falls für alle \(\theta \in \Theta\) gilt:
\[\E_\theta [T] = \theta\]
Sei \(\theta \in \Theta\) und \(T\) ein Schätzer. Der \emph{Bias} (erwartete Schätzfehler) von \(T\) im Modell \(\P_\theta\) ist definiert als:
\[\E_\theta[T]-\theta\]
Der mittlere quadratische Schätzfehler (MSE) von \(T\) im Modell \(\P_\theta\) ist definiert als:
\begin{align*}
	\text{MSE}_\theta[T] & = \E_\theta[(T-\theta)^2]                    \\
	\text{MSE}_\theta[T] & = \Var_\theta(T) + (\E_\theta[T] - \theta)^2
\end{align*}

\subsection{Maximum-Likelihood-Methode}
\subsubsection{Likelihood-Funktion, ML-Schätzer}
Die Likelihood-Funktion ist definiert als
\[L(x_1, \ldots, x_n; \theta) = \begin{cases}
		p(x_1, \ldots, x_n; \theta) \quad \text{(diskret)} \\
		f(x_1, \ldots, x_n; \theta) \quad \text{(stetig)}
	\end{cases} \]

\noindent Für jedes \(x_1, \ldots, x_n \in W\) sei \(t_{ML}(x_1, \ldots, x_n)\) der Wert, welcher die Funktion \(\Theta \mapsto L(x_1, \ldots, x_n; \theta)\) maximiert. Ein Maximum-Likelihood-Schätzer ist dann definiert als
\[T_{ML} = t_{ML}(X_1, \ldots, X_n)\]

\subsubsection{Anwendung der Methode}
Die Maximum-Likelihood-Methode ist ein Weg, um systematisch einen Schätzer zu bestimmen.
\begin{enumerate}
	\item Gemeinsame Dichte/Verteilung der ZV finden
	\item Bestimme davon die Log-Likelihood-Funktion\\ \(f(\theta) := \ln(L(x_1, \ldots, x_n;\theta))\)
	\item \(f(\theta)\) nach \(\theta\) ableiten
	\item Nullstelle von \(f'(\theta)\) finden
\end{enumerate}
Unter dem gefundenen \(\theta\) ist die Likelihood-Funktion maximal.

\section{Tests}
\begin{subbox}{Null- und Alternativhypothese}
	Die Nullhypothese \(H_0\) und die Alternativhypothese \(H_A\) sind zwei Teilmengen \(\Theta_0 \subseteq \Theta, \Theta_A \subseteq \Theta\) wobei \(\Theta_0 \cap \Theta_A = \varnothing\). Eine Hypothese heisst \textit{einfach}, falls die Teilmenge aus einem einzelnen Wert besteht; sonst \textit{zusammengesetzt}.
\end{subbox}

\begin{mainbox}{Definition Test}
	Ein Test ist ein Tupel \((T,K)\), wobei \(T\) eine \(ZV\) der Form \(T=t(X_1, \ldots, X_n)\) und \(K \subseteq \R\) eine deterministische Teilmenge von \(\R\) ist. Wir nennen \(T\) die \textit{Teststatistik} und \(K\) den \textit{Verwerfungsbereich} oder kritischen Bereich.
\end{mainbox}

Wir wollen nun anhand der Daten \((X_1(\omega), \ldots, X_n(\omega))\) entscheiden, ob die Nullhypothese akzeptiert oder verworfen wird. Zuerst berechnen wir die Teststatistik \(T(\omega) = t(X_1(\omega), \ldots, X_n(\omega))\) und gehen dann wie folgt vor:
\begin{itemize}
	\item Die Hypothese \(H_0\) wird \textit{verworfen}, falls \(T(\omega) \in K\).
	\item Die Hypothese \(H_0\) wird \textit{akzeptiert}, falls \(T(\omega) \notin K\).
\end{itemize}
\begin{subbox}{Fehler 1. und 2. Art}
	Ein Fehler 1. Art ist, wenn \(H_0\) fälschlicherweise verworfen wird, obwohl sie richtig ist.
	\[\P_\theta[T \in K], \quad \theta \in \Theta_0\]
	\noindent Ein Fehler 2. Art ist, wenn \(H_0\) fälschlicherweise akzeptiert wird, obwohl sie falsch ist.
	\[\P_\theta[T\notin K] = 1 - \P_\theta[T \in K], \quad \theta \in \Theta_A\]
\end{subbox}
\subsection{Signifikanzniveau und Macht}
Ein Test hat Signifikanzniveau \(a \in [0,1]\) falls
\[\forall \theta \in \Theta_0 \: \P_\theta[T \in K] \le a\]
Es ist meist unser primäres Ziel, die Fehler 1. Art zu minimieren.

Das sekundäre Ziel ist, Fehler 2. Art zu vermeiden. Hierfür definieren wir die Macht eines Tests als Funktion:
\[\beta : \Theta_A \mapsto [0,1], \quad \theta \mapsto \P_\theta[T \in K]\]
Zu beachten ist, dass eine kleine Wahrscheinlichkeit für einen Fehler 2. Art einem \textit{grossen} \(\beta\) entspricht.

\subsection{Konstruktion von Tests}
Wir nehmen an, dass \(X_1, \ldots, X_n\) diskret oder gemeinsam stetig unter \(\P_{\theta_0}\) und \(\P_{\theta_A}\) sind, wobei \(\theta_0 \ne \theta_A\) einfach sind.

\noindent Der Likelihood-Quotient ist somit wohldefiniert:
\[R(x_1, \ldots, x_n) = \frac{L(x_1,\ldots, x_n;\theta_A)}{L(x_1, \ldots, x_n;\theta_0)}\]
(Falls \(L(x_1, \ldots, x_n; \theta_0) = 0\) setzen wir \(R(x_1, \ldots, x_n) = +\infty\).) Wenn \(R \gg 1\), so gilt \(H_A > H_0\) und analog \(R \ll 1 \implies H_A < H_0\).

\begin{subbox}{Likelihood-Quotient-Test}
	Der Likelihood-Quotient-Test (LQ-Test) mit Parameter \(c \ge 0\) ist definiert durch:
	\[T = R(x_1, \ldots, x_n) \quad \text{und} \quad K = (c, \infty]\]
\end{subbox}
Der LQ-Test ist optimal, da jeder andere Test mit kleinerem Signifikanzniveau auch eine kleinere Macht hat (Neyman-Pearson-Lemma).

\subsection{p-Wert}
Sei \(T = t(X_1, \ldots, X_n)\) eine Teststatistik und \((T,K_t)_{t\ge 0}\) eine Familie von Tests.

\begin{subbox}{Geordnete Teststatistik}
	Eine Familie von Tests heisst geordnet bzgl. \(T\) falls \(K_t \subset \R\) und \(s \le t \implies K_t \subset K_S\). Beispiele:
	\begin{itemize}
		\item \(K_t = (t, \infty)\) (rechtsseitiger Test)
		\item \(K_t = (-\infty, -t)\) (linksseitiger Test)
		\item \(K_t = (-\infty, -t) \cup (t, \infty)\) (beidseitiger Test)
	\end{itemize}
\end{subbox}

\begin{mainbox}{Definition p-Wert}
	Sei \(H_0: \theta = \theta_0\) eine einfache Nullhypothese. Sei \((T, K_t)_{t\ge 0}\) eine geordnete Familie von Tests. Der \(p\)-Wert ist definiert als ZV \(G(t)\), wobei
	\[G: \R_+ \mapsto [0,1], \quad G(t) = \P_{\theta_0}[T \in K_t]\]
\end{mainbox}
Der \(p\)-Wert hat folgende Eigenschaften:
\begin{enumerate}
	\item Sei \(T\) stetig und \(K_t = (t, \infty)\). Dann ist der \(p\)-Wert unter \(\P_{\theta_0}\) auf \([0,1]\) gleichverteilt.
	\item Für einen \(p\)-Wert \(\gamma\) gilt, dass alle Tests mit Signifikanzniveau \(\alpha > \gamma\) die Nullhypothese verwerfen.
\end{enumerate}

Insgesamt gilt also:
\[\text{kleiner } p\text{-Wert} \implies H_0 \text{ wird wahrscheinlich verworfen} \]

\section{Aufgaben}
\subsection{Multiple Choice}

Seien \(X,Y\) zwei ZV mit gemeinsamer Dichte \(f_{X,Y}\). Welche Aussage ist korrekt?
\begin{itemize}
	\item[\checkmark] \(X,Y\) sind immer stetig
	\item[\(\square\)] Die ZV sind nicht notwendigerweise stetig.
\end{itemize}

\noindent
Seien \((X_i)_{i = 1}^n\) uiv. mit Verteilungsfunktion \(F_{X_i} = F\). Was ist die Verteilungsfunktion von \(M = \text{max}(X_1,...,X_n)\)?
\begin{itemize}
	\item[\checkmark] \(F_M(a) = F(a)^n\)
	\item[\(\square\)] \(F_M(a) = 1 - F(a)^n\)
	\item[\(\square\)] \(F_M(a) = (1 - F(a))^n\)
\end{itemize}

\noindent
Seien \(X, Y\) unabhängig und lognormalverteilt (\(\ln X, \ln Y\) sind normalverteilt). Welche Aussage ist korrekt?
\begin{itemize}
	\item[\checkmark] \(XY\) ist lognormalverteilt
	\item[\(\square\)] \(XY\) ist normalverteilt
	\item[\(\square\)] \(e^{X + Y}\) ist normalverteilt
\end{itemize}

\subsection{Aufgaben Wahrscheinlichkeit}
\subsubsection*{\texorpdfstring{Dichte von \(\max(X_1,X_2)\)}{Dichte von max()}}

Seien \(X_1, X_2 \sim \mathcal{U}[0,1]\) unabhängige ZV und sei \(X = \max (X_1, X_2)\). Berechne die Dichtefunktion von \(X\) und \(\P[X_1 \leq x \mid X \geq y]\).
\begin{align*}
	F_X(t) & = \P[\max(X_1, X_2) \leq t]                                                                                                              \\ &= \P[X_1 \leq t] \cdot \P[X_2 \leq t] = F_{X_1}(t) \cdot F_{X_2}(t) \\
	f_X(t) & = \frac{d}{dt} F_{X_1}(t) \cdot F_{X_2}(t) = \frac{d}{dt} t^2 \cdot \mathbb{I}_{0 \leq t \leq 1} = 2t \cdot \mathbb{I}_{0 \leq t \leq 1}
\end{align*}

Für die Wahrscheinlichkeit brauchen wir eine Fallunterscheidung: \smallskip

\begin{enumerate}
	\item \(x < 0\) oder \(1 < x\):
	      \[\mathbb{P}[X_1 \leq x \mid X \geq y] = 0\]
	\item \(0 \leq x \leq y \leq 1\):
	      \[\frac{\mathbb{P}[X_1 \leq x \cap X \geq y]}{\mathbb{P}[X \geq y]} = \frac{x(1-y)}{1 - y^2}\]
	\item \(0 \leq y \leq x \leq 1\):
	      \[\frac{\mathbb{P}[X_1 \leq x \cap X \geq y]}{\mathbb{P}[X \geq y]} = \frac{x - y^2}{1 - y^2}\]
\end{enumerate}

\subsubsection*{Gemeinsame Dichte}

Bestimme die gemeinsame Dichte von \(P \sim \mathcal{U}[0,1]\) und \(H \sim \mathcal{U}[0,P]\). Wir wissen:
\[f_P(p) = \mathbb I_{p \in [0,1]} \quad f_{H | P}(h \mid p) = \frac{1}{p} \cdot \mathbb{I}_{h \in [0,p]}\]

\noindent
Somit ist:
\[f_{P, H} (p, h) = f_P(p) \cdot f_{H | P}(h \mid p) = \frac{1}{p} \cdot \mathbb I_{0 \leq h \leq p \leq 1}\]

\subsubsection*{Zentraler Grenzwertsatz}
Sei \(\bar X = \frac{1}{n} \sum_{i=1}^n X_i\) mit \(X_1,...,X_n\) uiv. und \(\sigma_{X_i} = 6, \mu\). Zeige, dass für \(n\) gross genug gilt:
\[\P[|\bar X - \mu| \leq 1] \approx 2 \Phi \left[\frac{\sqrt{n}}{6} \right] - 1\]

\noindent
Hierfür verwenden wir den zentralen Grenzwertsatz:
\begin{align*}
	\P[|\bar X - \mu| \leq 1] & = \P[|n \cdot \bar X - n \cdot \mu| \leq n]                                                                                          \\
	                          & = \P \left[\left|\frac{n \cdot \bar X - n \cdot \mu}{\sqrt{6^2 n}}\right| \leq \frac{n}{\sqrt{6^2 n}}\right]                         \\
	                          & = \P \left[\left|\frac{n \cdot \bar X - n \cdot \mu}{6 \sqrt n}\right| \leq \frac{\sqrt n}{6}\right]                                 \\
	                          & \approx \Phi \left[ \frac{\sqrt n}{6} \right] - \Phi \left[ -\frac{\sqrt n}{6} \right] = 2 \Phi \left[ \frac{\sqrt n}{6} \right] - 1
\end{align*}

\subsubsection*{Dichte via Erwartungswert}
Sei \(U \sim \mathcal{U}[0,1]\). Berechne die Dichte von
\[U' = a + (b-a)U\]
Wir definieren \(\tau(x) = \phi(a +(b-a)U)\). Dann verwenden wir
\begin{align*}
	\E[\tau(U)] & = \int_{-\infty}^\infty \tau(x) \mathbb{I}_{x\in [0,1]}\mathop{dx}              \\
	            & = \int_0^1 \phi(a + (b-a)x) \mathop{dx}                                         \\
	            & = \int_a^b \phi(y)\frac{1}{b-a} \mathop{dy}                                     \\
	            & = \int_{-\infty}^\infty \phi(y)\frac{1}{b-a} \mathbb{I}_{y\in[a,b]} \mathop{dy}
\end{align*}
Die Dichte von \(U'\) ist also \(\frac{1}{b-a} \mathbb{I}_{y\in[a,b]}\).

\subsection{Serie 13}
\paragraph{Q1.} Sei \( \Theta = [0, 1] \). Wir betrachten die Modellfamilie \( (\P_\theta)_{\theta \in \Theta} \), wobei \( X_1, \dots, X_n \) unter \( \P_\theta \) unabhängig, identisch verteilt sind mit \( X_1 \sim \mathrm{Geo}(\theta) \). Was ist die Likelihood-Funktion \( L(x_1, \dots, x_n; \theta) \) für \( x_1, \dots, x_n \in \{1, 2, \dots \} \)?
\begin{enumerate}[label=(\alph*)]
    \item \( (1 - \theta)^{x_1 + \dots + x_n} \)
    \item \( \theta^n \cdot (1 - \theta)^{x_1 + \dots + x_n} \)
    \item {\color{Green} \( \theta^n \cdot (1 - \theta)^{x_1 + \dots + x_n - n} \) }
    \item \( (1 - \theta)^{x_1 + \dots + x_n - n} \)
\end{enumerate}
{\color{Green} Für eine \( \mathrm{Geo}(\theta) \)-verteilte Zufallsvariable \( X \) (unter \( \P_\theta \) gilt \( \P_\theta[X = x] = \theta \cdot (1 - \theta)^{x - 1} \) für alle \( x \in \{1, 2, \dots \} \). Da die Zufallsvariablen \( X_1, \dots, X_n \) unabhängig sind, erhält man die Likelihood-Funktion
\begin{align*}
    L(x_1, \dots, x_n; \theta) &=  \P_\theta[X_1 = x_1, \dots, X_n = x_n ] \\
    &= \prod_{i = 1}^n \P_\theta[X_i = x_i] \\
    &= \theta^n \cdot (1 - \theta)^{x_1 + \dots + x_n - n}
\end{align*}}

\paragraph{Q2.} Weiterhin sei \( \Theta = [0, 1] \) und \( X_1, \dots, X_n \) seien unter \( \P_\theta \) unabhängig, identisch verteilt mit \( X_1 \sim \mathrm{Geo}(\theta) \). Was ist der Maximum-Likelihood-Schätzer \( T_{ML} \) für \( \theta \)?
\begin{enumerate}[label=(\alph*)]
    \item \( \frac{X_1 + \dots + X_n}{n} \)
    \item {\color{Green} \( \frac{n}{X_1 + \dots + X_n} \)}
    \item \( \frac{X_1 + \dots + X_n + n}{n} \)
    \item \( \frac{n}{X_1 + \dots + X_n + n} \)
\end{enumerate}
{\color{Green} In der vorherigen Frage haben wir gezeigt, dass die log-Likelihood-Funktion gegeben ist durch
\[ n \cdot \log(\theta) + (x_1 + \dots + x_n - n) \cdot \log(1 - \theta) \]
Wir setzen nun die Ableitung der log-Likelihood-Funktion nach \( \theta \) gleich \( 0 \) und erhalten
\begin{align*}
    & \frac{n}{\theta} - \frac{x_1 + \dots + x_n - n}{1 - \theta} = 0 \\
    \iff & n - n \theta = (x_1 + \dots + x_n) \cdot \theta - n \theta \\
    \iff & \theta = \frac{n}{x_1 + \dots + x_n }
\end{align*}
und somit
\[ T_{ML} = \frac{n}{X_1 + \dots + X_n} \]
}

\paragraph{Q3.} Sei \( \Theta = (\theta, \infty) \). Wir betrachten die Modellfamilie \( (P_\theta)_{\theta \in \Theta} \), wobei \( X_1, \dots, X_n \) unter \( \P_\theta \) unabhängig, identisch verteilt sind mit \( X_1 \sim \mathrm{Exp}(\theta) \). Was ist die Likelihood-Funktion \( L(x_1, \dots, x_n; \theta)  \) für \( x_1, \dots, x_n \geq 0 \)?
\begin{enumerate}[label=(\alph*)]
    \item \( e^{-\theta(x_1 + \dots + x_n)} \)
    \item \( \theta \cdot e^{-\theta(x_1 + \dots + x_n)} \)
    \item {\color{Green} \( \theta^n \cdot e^{-\theta(x_1 + \dots + x_n)} \)}
    \item \( n \theta^n \cdot e^{-\theta(x_1 + \dots + x_n)} \)
\end{enumerate}
{\color{Green} Eine \( \mathrm{Exp}(\theta) \)-verteilte Zufallsvariable \( X \) (unter \( \P_\theta \)) hat Dichte \( f_X(x) = \theta e^{-\theta x} 1_{x \geq 0} \). Da die Zufallsvariablen \( X_1, \dots, X_n \) unabhängig sind, haben die Zufallsvariablen \( X_1, \dots, X_n \) eine gemeinsame Dichte und wir erhalten die Likelihood-Funktion
\begin{align*}
    L(x_1, \dots, x_n; \theta) &= f_{X_1, \dots, X_n}(x_1, \dots, x_n; \theta) \\
    &= \prod_{i = 1}^n \theta e^{-\theta x_i} 1_{x_i \geq 0} \\
    &= \theta^n e^{-\theta(x_1 + \dots + x_n)} 1_{x_1, \dots, x_n \geq 0}
\end{align*}}

\paragraph{Q4.} Weiterhin sei \(\Theta = (\theta, \infty) \) und \( X_1, \dots , X_n \) seien unter \( \P_\theta \) unabhängig, identisch verteilt mit \( X_1 \sim \mathrm{Exp}(\theta) \). Was ist der Maximum-Likelihood-Schätzer \( T_{ML} \) für \( \theta \)?
\begin{enumerate}[label=(\alph*)]
    \item {\color{Green} \( \frac{n}{X_1 + \dots + X_n} \)}
    \item \( X_1 + \dots + X_n \)
    \item \( \frac{X_1 + \dots + X_n}{n} \)
    \item \( \frac{1}{X_1 + \dots + X_n} \)
\end{enumerate}
{\color{Green} In der vorherigen Frage haben wir gezeigt, dass die log-Likelihood-Funktion gegeben ist durch
\[ n \cdot \log(\theta) - \theta(x_1 + \dots + x_n) \]
Wir setzen nun die Ableitung der log-Likelihood-Funktion nach \( \theta \) gleich \( 0 \) und erhalten
\[ \frac{n}{\theta} - (x_1 + \dots + x_n) = 0 \iff \theta = \frac{n}{x_1 + \dots + x_n} \]
und somit
\[ T_{ML} = \frac{n}{X_1 + \dots + X_n} \]}

\paragraph{Q5.} Sei \( X \sim \chi_n^2 \). Was ist der Erwartungswert \( \E[X] \)?
\begin{enumerate}[label=(\alph*)]
    \item \( 1 \)
    \item \( 2 \)
    \item \( \frac{n}{2} \)
    \item {\color{Green} \( n \)}
    \item \( n^2 \)
\end{enumerate}
{\color{Green} \( X \) hat die gleiche Verteilung wie \( Z_1^2 + \dots + Z_n^2 \), wobei \( Z_1, \dots, Z_n \) u.i.v. \(\sim \mathcal{N}(0,1) \) sind. Aus Linearität haben wir
\[ \E[X] = \E[Z_1^2] + \dots + \E[Z_n^2] = n \E[Z_1^2] = n \]}

\paragraph{Q6.} Sei \( X_1, \dots, X_n \) u.i.v. \( \sim \mathcal{N}(0, 1)\). \textit{(Mehrere richtige Antworten möglich.)}
\begin{enumerate}[label=(\alph*)]
    \item {\color{Green} \( X_1^2 + \dots + X_n^2 \sim \chi_n^2 \)}
    \item \( (X_1 + \dots + X_n)^2 \sim \chi_n^2 \)
    \item {\color{Green} \( \frac{1}{n} (X_1 + \dots + X_n)^2 \sim \chi_1^2 \)}
    \item {\color{Green} \( X_1^2 + X_2^2 \sim \mathrm{Exp}(\frac{1}{2}) \)}
\end{enumerate}

\paragraph{F1. [MLE I: Stetige Verteilung]}
Wir betrachten eine stetige Verteilung mit Dichte
\[ f(x) = \begin{cases}
    \frac{\theta}{x^{\theta + 1}} & x \geq 1 \\
    0 & x < 1
\end{cases} \]
wobei \( \theta > 0 \) ein unbekannter Parameter ist. Wir wollen den Parameter \( \theta \) mit Hilfe eines Datensatzes schätzen.
Sei \( X_1, \dots, X_n \) eine Stichprobe von unabhängigen Zufallsvariablen, welche alle die Dichte \( f \) besitzen. Bestimme die Likelihood- und log-Likelihood-Funktion.
Bestimme den zugehörigen Maximum-Likelihood-Schätzer für \( \theta \). Schreibe zuerst die allgemeine Formel für \( n \) Beobachtungen hin und berechne dann den Schätzwert für die folgende konkrete Stichprobe:
\begin{center}
    \begin{tabular}{|ccccc|}
        \hline
        \( x_1 \) & \( x_2 \) & \( x_3 \) & \( x_4 \) & \( x_5 \)  \\
        \hline
        \( 12.0 \) & \( 4.0 \) & \( 6.9 \) & \( 27.9 \) & \( 15.4 \) \\
        \hline
    \end{tabular}
\end{center}
{\color{Green}
\begin{enumerate}[label=(\alph*)]
    \item \color{Green} Die Likelihood-Funktion ergibt sich aus dem Produkt der Dichten. Für \( x_1, \dots, x_n \geq 1 \) erhalten wir
    \begin{align*}
        L(x_1, \dots, x_n; \theta) &= \prod_{i = 1}^n f(x_i) \\
        &= \prod_{i=1}^n \frac{\theta}{x_i^{\theta + 1}} \\
        &= \theta^n \frac{1}{(\prod_{i = 1}^{n} x_i)^{\theta + 1}}
    \end{align*}
    Falls \( x_i < 1 \) für ein \( 1 \leq i \leq n \), ist die Likelihood-Funktion gleich \( 0 \), wir können uns also auf den Fall \( x1, \dots, x_n \geq 1 \) beschränken.
    Die log-Likelihood-Funktion erhalten wir durch Logarithmieren obiger Formel als
    \begin{align*}
        l(x_1, \dots, x_n; \theta) &= \log L(x_1, \dots, x_n; \theta) \\
        &= n \log \theta - (\theta + 1) \sum_{i = 1}^n \log x_i
    \end{align*}
    \item \color{Green} Ableiten und Nullsetzen der log-Likelihood-Funktion ergibt
    \[ \frac{\partial}{\partial \theta} l(x_1, \dots, x_n; \theta) = \frac{n}{\theta} - \sum_{i = 1}{n} \log x_i = 0 \]
    für \( \theta^* = \frac{n}{\sum_{i = 1}^n \log x_i} \). Für \( \theta < \theta^* \) ist die Ableitung strikt positiv, für \( \theta > \theta^* \) strikt negativ, es handelt sich also um das Maximum. Also ist der Maximum-Likelihood-Schätzer
    \[ T_{ML} = \frac{n}{\sum_{i = 1}^{n} \log X_i} = \frac{1}{\frac{1}{n} \sum_{i = 1}^{n} \log X_i} \]
    Der realisierte Schätzwert für die gegebenen Daten ist dann
    \[ t_{ML} = \frac{5}{\sum_{i = 1}^5 \log x_i} = 0.4214 \]
\end{enumerate}
}

\paragraph{F3. [Beispiel 8.14]}
Die Australier Mr. Smith und Dr. Thurston streiten sich über das Durchschnittsgewicht von Straußeneiern. Beide sind damit einverstanden, das Gewicht approximativ als normalverteilt aufzufassen. Mr. Smith behauptet, das mittlere Gewicht sei 1100g, während Dr. Thurston darauf besteht, es liege im Schnitt bei 1200g.
Sie reisen also nach Afrika und suchen Straußeneier. Da diese aber gut versteckt sind, finden sie nur \( n = 8 \) Eier, deren Gewichte (in g) 1090, 1150, 1170, 1080, 1210, 1230, 1180, 1140 betragen.
\begin{enumerate}[label=(\alph*)]
    \item Dr. Thurston schlägt vor, Mr. Smiths Behauptung als Hypothese \( \mu = \mu_0 = 1100 \) gegen seine Alternative \( \mu > 1100 \) auf dem 5\%-Niveau zu testen.
    \item Mr. Smith schlägt vor, Dr. Thurstons Behauptung als Hypothese \( \mu = \mu_1 = 1200 \) gegen seine Alternative \( \mu < 1200 \) auf dem 5\%-Niveau zu testen.
\end{enumerate}
Die Varianz \( \sigma^2 \) ist beiden bekannt und beträge (in g) \( \sigma = 55 \).
{\color{Green}
\begin{enumerate}[label=(\alph*)]
    \item Der Mittelwert der 8 Eier ist:
    \[ \bar{x_n} = \frac{1}{n} \sum_{k = 1}^n x_k = \frac{1}{8} \sum_{k = 1}^8 x_k = 1156.25 \]
    Der kritische Wert für einseitigen Test auf dem 5\%-Niveau ist \( z_{0.95} = 1.645 \). Der Teststatistik ist:
    \[ T_{Th} = \frac{\bar{x_n} - \mu_0}{\frac{\sigma}{\sqrt{n}}} = \frac{1156.25 - 1100}{\frac{55}{\sqrt{8}}} = 2.89 \]
    Da \( T_{Th} > z_{0.95} \), wird die Nullhypothese \( \mu = 1100 \) auf dem 5\%-Niveau verworfen.
    \item Der Mittelwert der 8 Eier bleibt:
    \[ \bar{x_n} = \frac{1}{n} \sum_{k = 1}^n x_k = \frac{1}{8} \sum_{k = 1}^8 x_k = 1156.25 \]
    Der kritische Wert für einseitigen Test auf dem 5\%-Niveau ist \( z_{0.05} = -1.645 \). Der Teststatistik ist:
    \[ T_{Sm} = \frac{\bar{x_n} - \mu_1}{\frac{\sigma}{\sqrt{n}}} = \frac{1156.25 - 1200}{\frac{55}{\sqrt{8}}} = -2.25 \]
    Da \( T_{Sm} < z_{0.05} \), wird die Nullhypothese \( \mu = 1200 \) auf dem 5\%-Niveau verworfen.
\end{enumerate}
Dieses Beispiel illustriert sehr schön die Bedeutung der Wahl von Hypothese und Alternative und auch ihre asymmetrische Behandlung. Mit dem ersten Test würde man Dr. Thurston Recht geben, mit dem zweiten hingegen Mr. Smith. Und das passiert trotz völlig identischen Daten!
}


\section{Quellen}
Dieses Cheatsheet wurde stark vom \href{https://n.ethz.ch/~dcamenisch/summaries}{Cheatsheet von Danny Camenisch} inspiriert. Ausserdem stammen Teile der Tabellen aus dem Buch ``Formeln, Tabellen und Konzepte''. Die Definitionen sind grösstenteils vom offiziellen Vorlesungsskript (V. Tassion) übernommen.


\clearpage
\section{Tabellen}

\subsection{Grenzwerte}
\begin{center}
	\begin{tabularx}{\linewidth}{XX}
		\toprule
		$\limxi \frac{e^x}{x^m} = \infty$                      & $\limxn xe^x = 0$                        \\
		$\limxi (1+x)^{\frac{1}{x}} = 1$                       & $\limxo (1+x)^{\frac{1}{x}} = e$         \\
		$\limxi (1+\frac{1}{x})^b = 1$                         & $\limxi n^{\frac{1}{n}} = 1$             \\
		$\limxo \frac{e^x-1}{x} = 1$                           & $\limxi (1-\frac{1}{x})^x = \frac{1}{e}$ \\
		$\lim_{x\to\pm\infty} (1 + \frac{k}{x})^{mx} = e^{km}$ & $\limxi (\frac{x}{x+k})^x = e^{-k}$      \\
		$\limxo \frac{\log 1 - x}{x} = -1$                     & $\limxo x \log x = 0$                    \\
		$\limxo \frac{e^{ax}-1}{x} = a$                        & $\limxo \frac{\ln(x+1)}{x} = 1$          \\
		$\lim_{x\to 1} \frac{\ln(x)}{x-1} = 1$                 & $\limxi \frac{\log(x)}{x^a} = 0$         \\
		\bottomrule
	\end{tabularx}
\end{center}

\begin{mainbox}{Partielle Integration}
	\vspace{-12pt}
	$$\int f'(x) g(x) \mathop{dx} = f(x)g(x) - \int f(x) g'(x) \mathop{dx}$$
\end{mainbox}
\begin{itemize}
	\item Meist gilt: Polynome ableiten ($g(x)$), wo das Integral periodisch ist ($\sin, \cos, e^x$,...) integrieren ($f'(x)$)
	\item Teils: mit $1$ multiplizieren, um partielle Integration anwenden zu können (z.B. im Fall von $\int \log(x) \mathop{dx}$)
\end{itemize}
\begin{mainbox}{Substitution}
	Um $\int_a^b f(g(x)) \mathop{dx}$ zu berechnen: Ersetze $g(x)$ durch $u$ und integriere $\int_{g(a)}^{g(b)} f(u) \frac{\text{d}u}{g'(x)}$.
\end{mainbox}
\begin{itemize}
	\item $g'(x)$ muss sich herauskürzen, sonst nutzlos.
	\item Grenzen substituieren nicht vergessen.
	\item Alternativ: unbestimmtes Integral berechnet werden und dann $u$ wieder durch $x$ substituieren.
\end{itemize}

\subsection{Ableitungen}
\begin{center}
	% the c>{\centering\arraybackslash}X is a workaround to have a column fill up all space and still be centered
	\begin{tabularx}{\linewidth}{c>{\centering\arraybackslash}Xc}
		\toprule
		$\mathbf{F(x)}$                        & $\mathbf{f(x)}$          & $\mathbf{f'(x)}$         \\
		\midrule
		$\frac{x^{-a+1}}{-a+1}$                & $\frac{1}{x^a}$          & $\frac{a}{x^{a+1}}$      \\
		$\frac{x^{a+1}}{a+1}$                  & $x^a \ (a \ne 1)$        & $a \cdot x^{a-1}$        \\
		$\frac{1}{k \ln(a)}a^{kx}$             & $a^{kx}$                 & $ka^{kx} \ln(a)$         \\
		$\ln |x|$                              & $\frac{1}{x}$            & $-\frac{1}{x^2}$         \\
		$\frac{2}{3}x^{3/2}$                   & $\sqrt{x}$               & $\frac{1}{2\sqrt{x}}$    \\
		$-\cos(x)$                             & $\sin(x)$                & $\cos(x)$                \\
		$\sin(x)$                              & $\cos(x)$                & $-\sin(x)$               \\
		$\frac{1}{2}(x-\frac{1}{2}\sin(2x))$   & $\sin^2(x)$              & $2 \sin(x)\cos(x)$       \\
		$\frac{1}{2}(x + \frac{1}{2}\sin(2x))$ & $\cos^2(x)$              & $-2\sin(x)\cos(x)$       \\
		\multirow{2}*{$-\ln|\cos(x)|$}         & \multirow{2}*{$\tan(x)$} & $\frac{1}{\cos^2(x)}$    \\
		                                       &                          & $1 + \tan^2(x)$          \\
		$\cosh(x)$                             & $\sinh(x)$               & $\cosh(x)$               \\
		$\log(\cosh(x))$                       & $\tanh(x)$               & $\frac{1}{\cosh^2(x)}$   \\
		$\ln | \sin(x)|$                       & $\cot(x)$                & $-\frac{1}{\sin^2(x)}$   \\
		$\frac{1}{c} \cdot e^{cx}$             & $e^{cx}$                 & $c \cdot e^{cx}$         \\
		$x(\ln |x| - 1)$                       & $\ln |x|$                & $\frac{1}{x}$            \\
		$\frac{1}{2}(\ln(x))^2$                & $\frac{\ln(x)}{x}$       & $\frac{1 - \ln(x)}{x^2}$ \\
		$\frac{x}{\ln(a)} (\ln|x| -1)$         & $\log_a |x|$             & $\frac{1}{\ln(a)x}$      \\
		\bottomrule
	\end{tabularx}
\end{center}
\subsection{Weitere Ableitungen}
\begin{center}
	\begin{tabularx}{\linewidth}{>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
		\toprule
		$\mathbf{F(x)}$ & $\mathbf{f(x)}$             \\
		\midrule
		$\arcsin(x)$    & $\frac{1}{\sqrt{1 - x^2}}$  \\
		$\arccos(x)$    & $\frac{-1}{\sqrt{1 - x^2}}$ \\
		$\arctan(x)$    & $\frac{1}{1 + x^2}$         \\
		$x^x \ (x > 0)$ & $x^x \cdot (1 + \ln x)$     \\
		\bottomrule
	\end{tabularx}
\end{center}
\subsection{Integrale}
\begin{center}
	\begin{tabularx}{\linewidth}{>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
		\toprule
		$\mathbf{f(x)}$                              & $\mathbf{F(x)}$                                                  \\
		\midrule
		$\int f'(x) f(x) \mathop{dx}$                & $\frac{1}{2}(f(x))^2$                                            \\
		$\int \frac{f'(x)}{f(x)} \mathop{dx}$        & $\ln|f(x)|$                                                      \\
		$\int_{-\infty}^\infty e^{-x^2} \mathop{dx}$ & $\sqrt{\pi}$                                                     \\
		$\int (ax+b)^n \mathop{dx}$                  & $\frac{1}{a(n+1)}(ax+b)^{n+1}$                                   \\
		$\int x(ax+b)^n \mathop{dx}$                 & $\frac{(ax+b)^{n+2}}{(n+2)a^2} - \frac{b(ax+b)^{n+1}}{(n+1)a^2}$ \\
		$\int (ax^p+b)^n x^{p-1} \mathop{dx}$        & $\frac{(ax^p+b)^{n+1}}{ap(n+1)}$                                 \\
		$\int (ax^p + b)^{-1} x^{p-1} \mathop{dx}$   & $\frac{1}{ap} \ln |ax^p + b|$                                    \\
		$\int \frac{ax+b}{cx+d} \mathop{dx}$         & $\frac{ax}{c} - \frac{ad-bc}{c^2} \ln |cx +d|$                   \\
		$\int \frac{1}{x^2+a^2} \mathop{dx}$         & $\frac{1}{a} \arctan \frac{x}{a}$                                \\
		$\int \frac{1}{x^2 - a^2} \mathop{dx}$       & $\frac{1}{2a} \ln\left| \frac{x-a}{x+a} \right|$                 \\
		$\int \sqrt{a^2+x^2} \mathop{dx} $           & $\frac{x}{2}f(x) + \frac{a^2}{2}\ln(x+f(x))$                     \\
		\bottomrule
	\end{tabularx}
\end{center}
\clearpage

\renewcommand*{\arraystretch}{2.5}
\subsection{Diskrete Verteilungen}
\begin{center}
	\begin{tabularx}{\textwidth}{llXXXX}
		\toprule
		Verteilung       & Parameter                                   & \( \E[X] \) & \( \Var(X) \)       & \( p_X(t) \)         & \( F_X(t) \)                     \\
		\midrule
		Gleichverteilung & \makecell[l]{\( n \): Anzahl Ereignisse                                                                                                   \\ \( x_i \): Ereignisse} & \( \frac{1}{n} \sum_{i=1}^{n} x_i \) & \( \frac{1}{n} \sum_{i=1}^{n} x_i^2 - \frac{1}{n^2} \left(\sum_{i=1}^{n} x_i \right)^2 \) & \( \frac{1}{n} \) & \( \frac{|\{k:x_k \leq t\}|}{n} \) \\

		Bernoulli        & \( p: \) ErfolgsWK                          & \( p \)     & \( p \cdot (1-p) \) & \( p^t(1-p)^{1-t} \) & \( 1-p \) für \( 0 \leq t < 1 \) \\

		Binomial         & \makecell[l] {\( n \): Anzahl Versuche                                                                                                    \\ \( p: \) ErfolgsWK } & \( np \) & \( np(1-p) \) & \( \binom{n}{t}p^t(1-p)^{n-t} \) & \( \sum_{k=0}^{t} \binom{n}{k} p^k(1-p)^{n-k} \)  \\

		Geometrisch      & \makecell[l] { \( p \): ErfolgsWK                                                                                                         \\ \( t: \) Anzahl Versuche} & \( \frac{1}{p} \) & \( \frac{1-p}{p^2} \) & \( p(1-p)^{t-1} \) & \( 1-(1-p)^t\) \\

		Poisson          & \makecell[l]{ \( \lambda \): Erwartungswert                                                                                               \\ und Varianz} & \( \lambda \) & \( \lambda \) & \( \frac{\lambda^t}{t!}e^{-\lambda} \) & \( e^{-\lambda} \sum_{k=0}^{t} \frac{\lambda^{k}}{k!} \) \\

		\bottomrule
	\end{tabularx}
\end{center}

\bigskip
\subsection{Stetige Verteilungen}
\begin{center}
	\begin{tabularx}{\textwidth}{llXXXX}
		\toprule
		Verteilung               & Parameter                            & \( \E[X] \)                      & \( \Var(X) \)                    & \( f_X(t) \)                                                                                                                                  & \( F_X(t) \)                                  \\

		\midrule
		Gleichverteilung         & \( [a,b] \): Intervall               & \( \frac{a+b}{2} \)              & \( \frac{1}{12}(b-a)^2 \)        & \(\begin{cases} \frac{1}{b-a} &a \le x \le b \\ 0 & \text{sonst}\end{cases}\)                                                                                                                & \(\begin{cases} 0 & x\le a \\ \frac{t-a}{b-a} & a < x < b \\ 1 & x \ge b \end{cases}\)                \\

		Exponentialverteilung    & \( \lambda: \frac{1}{\E[X]} \)       & \( \frac{1}{\lambda} \)          & \( \frac{1}{\lambda^2} \)        & \( \begin{cases} \lambda e^{-\lambda t} & t \geq 0 \\ 0 & t < 0 \end{cases} \)                                                                                                              & \( \begin{cases} 1-e^{-\lambda t} & t>0 \\ 0 & t \leq 0\end{cases}\)               \\

		Normalverteilung         & \makecell[l]{\( \sigma^2 \): Varianz                                                                                                                                                                                                                                                                       \\ \( \mu: \E[X] \)} & \( \mu \) & \( \sigma ^2 \) & \( \frac{1}{\sqrt{2\pi \sigma^2} }e^{-{\frac{(t-\mu)^2}{2\sigma^2} }} \) & \( \frac{1}{\sigma {\sqrt{2\pi}}} \int_{-\infty}^t e^{-\frac{1}{2}\left( \frac{y-\mu}{\sigma} \right) ^2} \mathrm{d} y \) \\

		\( \chi ^2 \)-Verteilung & \( n \): Freiheitsgrad               & \( n \)                          & \( 2n \)                         & \( \frac{1}{2^{\frac{n}{2}}\Gamma (\frac{n}{2})} t^{\frac{n}{2}-1} e^{-\frac{t}{2}} \text{ für } t>0\)                                        & \(P\left( \frac{n}{2}, \frac{t}{2}\right)  \) \\

		t-Verteilung             & \( n \): Freiheitsgrad               & \( \begin{cases} 0 & n>1 \\ \text{undef.} & \text{sonst} \end{cases} \) & \( \begin{cases} \frac{n}{n-2} & n> 2 \\ \infty & 1<n \leq 2 \\ \text{undef.} & \text{sonst} \end{cases} \) & \( \frac{\Gamma \left( \frac{n+1}{2} \right) }{\sqrt{n\pi } \cdot \Gamma (\frac{n}{2})} \left( 1+ \frac{t^2}{n} \right) ^{- \frac{n+1}{2}} \) & I'd rather not                                \\


		\bottomrule
	\end{tabularx}
\end{center}

\end{document}
